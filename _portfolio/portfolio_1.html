---
title: "Particle Tracking Velocimetry (PTV) using K-Nearest Neighbors (KNN)"
excerpt: "A gentle, informal implementation of PTV using KNN technique using negligible mathematical equations and a pinch of Python (code)<br>
<br>
<img src='/images/KNN_/teaser.jpg'>"
collection: portfolio
---
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Python Code Block with Auto Syntax Highlighting</title>

    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
	
	<style> <! .... Style video container ....>
	        /* Centering the video */
        .video-container {
            display: flex;
            justify-content: center;
            align-items: center;
            width: 100%;
            padding: 20px;
        }
	</style>
    <style><!....... Style the code block ....>
        /* Style for the code block container */
        .code-container {
            position: relative;
            background-color: #282c34;
            border-radius: 8px;
            padding: 15px;
            margin: 30px auto; /* Adds spacing before & after */
            max-width: 60%; /* Responsive width */
            max-height: 300px; /* Set height limit */
            overflow: auto; /* Enables horizontal & vertical scrollbars */
            box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.2);
        }

        /* Copy button */
        .copy-btn {
            position: absolute;
            top: 10px;
            right: 10px;
            background: #61dafb;
            color: black;
            border: none;
            padding: 5px 10px;
            cursor: pointer;
            font-size: 14px;
            border-radius: 5px;
            transition: 0.3s;
        }

        .copy-btn:hover {
            background: #4fa3d1;
        }

        /* Code styling */
        pre {
            margin: 0;
            padding: 15px;
            white-space: pre; /* Prevents automatic wrapping */
            overflow: auto; /* Enables scrolling */
        }

        code {
            font-size: 16px;
        }
    </style>
	<style> <! .... for the image containers ....>
	/* Figure wrapper to center everything */
        .image-wrapper {
            display: flex;
            flex-direction: column;
            align-items: center; /* Centers the figure */
            justify-content: center;
            text-align: center; /* Ensures caption is centered */
            margin-bottom: 10px; /* Adds spacing between groups */
        }
		
        /* Container for images */
        .image-container {
            display: flex; /* Align images in a row */
            justify-content: center; /* Center images */
            align-items: center; /* Align images vertically */
            flex-wrap: wrap;  Allows wrapping for responsiveness */
            width: 100%; /* Adjusts width */
            max-width: 900px; /* Prevents excessive stretching */
            border: 1px solid black; /* Border around the images */
            padding: 1px; /* Space inside the border */
            box-sizing: border-box; /* Ensures padding doesn’t increase size */
            margin: 1px auto; /* Centers the container */
            gap: 5px; /* Adds spacing between images */
        }
		
        /* Single image layout */
        .single-image .image-container img {
            width: 40%;
			margin-bottom: -1px;
			/* Full width for single image */
        }
        /* Styling for images */
        .two-columns .image-container img {
            width:49%; /* Two-column layout by default */
            margin-bottom: -1px;
        }

        /* Three-column layout */
        .three-columns .image-container img {
            width: 32%; /* Three images per row */
			margin-bottom: -1px;
        }
		/* Caption styling */
        .image-caption {
            font-style: italic;
            color: black;
            margin-top: 10px; /* Adds spacing above the caption */
            font-size: 0.9em;
        }

        /* Responsive: Stack images on smaller screens */
        @media (max-width: 600px) {
			.image-container{
                flex-direction: column; /* Stack images on smaller screens */
                width:100%; /* Adjust for smaller screens */
            }
            .image-container img {
                width: 100%; /* Full width when stacked */
            }
        }
	</style
</head>

	
</head>
<body>

	<! Add all the stuff herer ......>
	
	<p style="text-align:justify;">
	For soft, condensed matter physics, tracking particulate matter in flows are a cornerstone for understanding fluid behavior. Whether it understand fluid-solid interactions or whether it for understanding the fluid flow itself: -- where the particles in the fluid act as tracers. Thus, if we suspend tiny, lightweight particles in any fluid and track their motion, we can infer the flow behavior of the fluid itself, even if the fluid is transparent … sounds cool right!!
	</P>
	
	<p style="text-align:justify;">
	If you have the liberty to dump larger concentration of particles into the fluid, then the fluid flow redistributes the particles in different regions of the fluid based on their velocity. Thus, by cross correlating the changes in positions of a bunch of these particles we can infer their speeds (for the curious ones.… this correlations process resembles convolution kernels a lot!!!.) This method is now popularly known as Particle Image Velocimetry (PIV).
	</p>
	
	<p style="text-align:justify;">
	PIV is extremely good for cases where the particles obediently follow the fluid flow without any active involvement. Thus, to measure the fluid flow, we can map the motion of an ensemble of these particles without the need for tracking individual particle.
	</p>

	<p style="text-align:justify;">
	Many a time, the particles are actively involved and modify the fluid dynamics through hydrodynamic perturbations. In such cases, measuring the motion of nearly every particle, becomes very important. To do so, we use another very interesting technique called as the Particle Tracking Velocimetry (PTV). <br>
	PTV is performed by taking multiple snapshots in quick succession of a moving particle and correlating their position across these multiple snapshots. So, how does this work?? 
	</p>
	  
	<!........ Figure 1 .......>
	<figure class="image-wrapper three-columns">
    <div class="image-container">
        <img src="KNN_/set_new.png" alt="parity_living_area.png">
        <img src="KNN_/set_new_far_trace.png" alt="parity_plot_area.png">
		<img src="KNN_/set_new_far_trace1.png" alt="parity_external_storage.png">
    </div>
	<figcaption class="image-caption"> Fig 1: a) Superimposed particle images from snapshots taken quickly, b) Superimposed particle images from snapshots taken with significant delay, c) Superimposed particle images from snapshots from (b) but with an intermdiate snap added between them</figcaption>
	</figure>
	
	
	<p style="text-align:justify;">
	To understand this let's look at fig 1 which shows the superposition of two consecutive images of the particle. One can notice three interesting things 
	<ol>
		<li> Between two successive snapshots, each particle has drifts by a distance which corresponds to its speed at that instant.If the snaps are taken in quick succession, you can identify the image pairs for each particle by eye between the snaps.(see fig 1(a))
		<li>If the particle has travelled too far,(when there is siginifant time delay in taking a snapshot) the particles position in the previous frame becomes difficult to trace by eye.(see fig 1(b))
		<li>However, if we add an intermediate snapshot, it become fairly easier to trace.(see fig 1(c)) 
	</ol>
	</p>
	
	
	<p style="text-align:justify;">
	This is because our brain which is actually a beautiful neural network searches for pattern to establish a single identity of a particle across several snapshots. And this pattern is the closest particle images between successive snapshots.<br>
	Our brain typically does this by estimating the distances of a particle’s image in a preceding snap to all particle images in the successive snap. Thus, ideally speaking, the nearest particle image in the successive snap will most likely be the image of itself!! (see fig 2). If the delay between two snaps is long, then the particles have traveled far from its position in the preceding snapshot enough to confuse our brains regarding the previous position of the particle. Hence we find it difficult to trace the original positions as in figure 1(b).
	</p>
	
	<! ..... Figure 2 ........>
	<figure class="image-wrapper single-image">
		<div class="image-container">
			<img src ="KNN_/set_new__arrow.png" class="center" >
		</div>
		<figcaption class="image-caption">Fig 2: Computing the distances of particle's image from preceding snap with all particle images from the succeeding snap (yellow arrows) the image of itself will be the shortest distance (blue arrow).</figcaption>
	</figure>
		
	<p style="text-align:justify;">
	Most statisticians/data gurus/analysts/science nerds might have figured by now how this trick can be mathematically implemented. Yes …… the answer is: using K Nearest Neighbors (KNN). Because the nearest neighbor (K=1) of any particle, is its OWN IMAGE from the consecutive snapshot. So, what is KNN?
	</p>
	
	<p style="text-align:justify;">
	KNN is a technique by which we can search of 'K' number of nearest neighbors of any entity. A simple example can be of a classroom full of children where each child can use a measurement tape and measure out the nearest 3 classmates that are sitting around them. For this, it stands as K=3. KNN is one of the most versatile methods in statistics because balances perfectly between performance and simplicity. Also, it is flexible enough to be used for classification as well as regression problems.
	</p>
	

	
	<! ........ Figure 3 ...... >
	<figure class="image-wrapper two-columns">
		<div class="image-container">
			<img src="KNN_/Plain.png" alt="snap.png">
			<img src="KNN_/Identify.png" alt="snap_indentification.png">
		</div>
		<figcaption class="image-caption"> Fig 3: a) Snapshot of a binary population of colloids. Those appearing white are the fluorescent particles which are 10 microns in size while the darker ones are non-fluorescent and are 7 microns in size, b) Using ImageJ we can identify the two populations quite accurately. The Fluorescent and the Non-fluorescent population are marked as <span style='color: #0000FF'>Blue</span> and <span style = 'color:#FF0000'>Red</span> points respectively in the overlay.</figcaption>
	</figure>

	<p style="text-align:justify;">
	At this stage I can demonstrate the power of KNN that drive PTV using a simple example from my PhD experiments. fig.3(a) shows a snapshot of two population of particles moving inside a vortex. Using a computer vision software called ImageJ, I can Identify each population pretty accurately and I indicate them with red and blue colors as shown in fig 3(b). Now, I perform the same operation on the succcessive snapshot as well and overlay the coordinates on the previous snaphot as shown in fig.4(a). You can appreicate how rapidly the succesive snapshot was taken as the particle have moved very little and this is visible more clearly in fig 4(b) where I zoom into the bottem left quadrant of the vortex. You can almost tell the image pairs for each particle just by looking at this fig!!
	</p>
	
	<!......... Figure 4 ...... >
	<figure class="image-wrapper two-columns">
		<div class="image-container">
			<img src="KNN_/Shift.png" alt="superimposed_succesive_snaps.png">
			<img src="KNN_/Shift_appriciate.png" alt="Zoomed_superimposition.png">
		</div>
		<figcaption class="image-caption"> Fig 4: a) The superimposed coordinated of the binary population from two successive snapshot. The snapshots have been taken very rapidly so the images of a single particle are almost overlapping. Just for perspective, The particle are travelling at c.a. 1 mm/s and the frames rate for imaging is 500 frames/sec b) The zoomed image of the lower left quadrant of the plot on the left. One can figure out the image pairs of most particles by eye.</figcaption>
	</figure> 
	<p style="text-align:justify;">
	Now, to implement KNN mathematically, I define a function (see the python code below) to search for the nearest neighbour as shown in the code block. The simplest searching stretegy is the ‘brute force’ method that firsts computes the distances between all possible images pairs. An image pair is created by picking 1 image from each frame. Then it chosses the ‘shortest’ distance. However, this is computationally very expensive (scales with square of the number of particles) and there are better algorithms like ‘KD tree’ and ‘ball tree’ that uses binary search to optimize the searching process(this scales linearly). I will discuss these algorithms in detail in some other post. 
	</p>
	<!-- Python Code Block -->
     <script>
        function copyCode(button) {
            let codeBlock = button.nextElementSibling.innerText;
            navigator.clipboard.writeText(codeBlock).then(() => {
                button.innerText = "Copied!";
                setTimeout(() => button.innerText = "Copy", 2000);
            });
        }
    </script>
	<div class="code-container">
        <button class="copy-btn" onclick="copyCode(this)">Copy</button>
        <pre><code class="language-python">
	# function to perform the Particle tracking via using KNN
	def vel_spins(frame1, frame2):
    '''
    This function uses KNN to match the particles with there image ain two consequetive frames
    Params:
        frame1: preceding snapshot
        frame2: succeeding snapsot
    '''
    
    # convert the positional data from the preceding snap into correct fromat of  [xi, yi] 
    counter_frame1 = [];
    for i in range(len(frame1.values)):
        counter_frame1.append(frame1.values[i][1:])
    frame1_train_data = np.array(counter_frame1) 
    
    # convert the positional data from the succeeding snap into correct fromat of  [xi, yi]
    counter_frame2 =[];
    for i in range(len(frame2.values)):
        counter_frame2.append(frame2.values[i][1:])
    frame2_train_data = np.array(counter_frame2)
    
    # ...... Implementation of the KNN to find the nearest neighbour
    
    # instatiate the KNN model setting K =1 and the algorithm of ball tree for more efficient search
    train_data = nnbrs(n_neighbors=1, algorithm='ball_tree')
    
    # train the model using the data from the preceding SnapShot
    train_data.fit(frame1_train_data)
    
    # Use this aforementioned trained model to predict the nearest neighbour of 
    # particle position in the succeeeding frame 
    # Here we implement the logic .... the nearest neighbour will be the image of itself!!!
    
    _,indices = train_data.kneighbors(frame2_train_data) 
    # indices above provide the tags (refernce) to connect the images of the same particles between two frames 
    
    # Use the above tags to re-arrange the particle positions from the preceding frame 
    add_X = []
    add_Y = []
    for x in indices:
        add_X.append(frame1.iloc[x]['X'])
        add_Y.append(frame1.iloc[x]['Y'])
    
    # attach the rearanged particle poisitons to the positions in the final frame 
    # to create a single master coordinate table by adding to frame 2
    frame2['XX'] = np.array(add_X)
    frame2['YY'] = np.array(add_Y)  
    
    frame2['dX'] = frame2['XX'] - frame2['X']
    frame2['dY'] = frame2['YY'] - frame2['Y']
    
    # compute  ''' Displacement''' for gnerating the velocity vectors
    frame2['dR'] = np.sqrt(frame2['dX']**2 + frame2['dY']**2)
    
    # return the master table (udated frame 2) 
    return frame2 
	
        </code></pre>
    </div>

   
	

	<p style="text-align:justify;">
	So, once the algorithm finds the image pair of each particle between the successive frames, it generates ‘indices’ as ‘tags’ with I then use to connect the correct image pair <br>. 
	Then I generate a ‘displacement’ vector, using the coordinates of the image pair. Unrealistic displacement vectors help me remove some wrongly connected image pairs (ofcourse) that I ignore due to their statistical irrelevance. Fig 5 shows the final velocity vector computed from the displacement vectors simply by dividing it with the time lag between the two successive snapshot completing the PTV process between two snaps. Now, doing this between all snapshot of the experiment, I can trace the motion of nearly all particles thorughput my entire experiment.
	</p>
	<! ........ Figure 5 ...... >
	<figure class="image-wrapper single-image">
			<div class="image-container">
				<img src ="KNN_/PTV_final.png" class="center" >
			</div>
			<figcaption class="image-caption">Fig 5: Using KNN (K=1) approach, image pairs of every particle is matched. The displacement between two successive snapshots of each particle between frames can now be measured now(indicated by the arrows) which also denote their respective velocity vectors </figcaption>
    </figure>
	<p style="text-align:justify;">
	A definite question that came to your mind by now: What snapshot rate is quick enough for the successful and efficient particle tracking? Well, for real experiments, particles are finite-sized and occupy space, hence do not overlap. We exploit this to say that imaging rate should be greater than D/V where D is the diameter of the particle and V is the speed of the fastest particle. Also, it should not be too quick: it should be slow enough for a particle detection software (like imageJ) to detect a change in the particle position based on the camera’s the image resolution. 
	</p>
	
	<p style="text-align:justify;">
	Finally, I am sure you are now curious about my experimental image and how the two populations of particles are beautifully segregated inside the ‘circular vortex’ ??? what is this vortex by the way??? and how are they even moving ???. All these answers are presented in my <a href = 'https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.131.178304'> <b>article</b></a> published in the <b>Physical Review Letters</b>. You can watch this video of the particles formaing the vortex and segregating spontaneously below.  
	</p>
	<center>
    <video class="video-container" width="400" height="400" controls>
        <source src="KNN_/BinaryDemixing_final.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
	<center>


</body>
